{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "wduQwiU4Pd85",
        "outputId": "459ab350-502d-4073-e1c4-d33124fdd287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The root node should be 'age' with Information Gain of 0.24674981977443933\n",
            "\n",
            "\n",
            "Entropy of 'age': 1.5774062828523454\n",
            "Entropy of 'income': 1.5566567074628228\n",
            "Entropy of 'student': 1.0\n",
            "Entropy of 'credit_rating': 1.2958363892911637\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bb8efd8883f3>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier , plot_tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "data = pd.read_excel(r'data78.xlsx')\n",
        "data\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def calculate_entropy(target):\n",
        "    entropy = 0\n",
        "    total_count = len(target)\n",
        "    class_counts = Counter(target)\n",
        "\n",
        "    for count in class_counts.values():\n",
        "        probability = count / total_count\n",
        "        entropy -= probability * np.log2(probability)\n",
        "\n",
        "    return entropy\n",
        "\n",
        "\n",
        "def calculate_information_gain(data, attribute_name):\n",
        "    target_values = data['buys_computer']\n",
        "    total_entropy = calculate_entropy(target_values)\n",
        "\n",
        "    attribute_values = data[attribute_name]\n",
        "    unique_attribute_values = set(attribute_values)\n",
        "    weighted_average_entropy = 0\n",
        "\n",
        "    for value in unique_attribute_values:\n",
        "        subset_indices = [i for i, val in enumerate(attribute_values) if val == value]\n",
        "        subset_target = [target_values[i] for i in subset_indices]\n",
        "        subset_entropy = calculate_entropy(subset_target)\n",
        "        weight = len(subset_indices) / len(attribute_values)\n",
        "        weighted_average_entropy += weight * subset_entropy\n",
        "\n",
        "    information_gain = total_entropy - weighted_average_entropy\n",
        "    return information_gain\n",
        "\n",
        "\n",
        "attribute_entropies = {}\n",
        "for attribute_name in data.keys():\n",
        "    if attribute_name != 'buys_computer':\n",
        "        attribute_values = data[attribute_name]\n",
        "        entropy = calculate_entropy(attribute_values)\n",
        "        attribute_entropies[attribute_name] = entropy\n",
        "\n",
        "\n",
        "attribute_information_gains = {}\n",
        "for attribute_name in data.keys():\n",
        "    if attribute_name != 'buys_computer':\n",
        "        information_gain = calculate_information_gain(data, attribute_name)\n",
        "        attribute_information_gains[attribute_name] = information_gain\n",
        "\n",
        "\n",
        "root_attribute = max(attribute_information_gains, key=attribute_information_gains.get)\n",
        "root_information_gain = attribute_information_gains[root_attribute]\n",
        "\n",
        "print(f\"The root node should be '{root_attribute}' with Information Gain of {root_information_gain}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "for attribute_name, entropy in attribute_entropies.items():\n",
        "    print(f\"Entropy of '{attribute_name}': {entropy}\")\n",
        "\n",
        "\n",
        "data1 = pd.read_excel(r'mlab4.xlsx')\n",
        "df = pd.get_dummies(data1, drop_first=True)\n",
        "\n",
        "model= DecisionTreeClassifier()\n",
        "model.fit(X,y)\n",
        "model.score(X, y)\n",
        "model.score(X,y)\n",
        "df\n",
        "plt.figure(figsize=(12, 8))\n",
        "plot_tree(clf, filled=True)\n",
        "plt.show()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = clf.predict(X_train)\n",
        "y_test_pred = clf.predict(X_test)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Accuracy on training data: {train_accuracy:.2f}\")\n",
        "print(f\"Accuracy on test data: {test_accuracy:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(12, ))\n",
        "plot_tree(clf, filled=True)\n",
        "plt.show()\n",
        "\n",
        "max_depth = 3\n",
        "clf = DecisionTreeClassifier(max_depth=max_depth)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = clf.predict(X_train)\n",
        "y_test_pred = clf.predict(X_test)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Accuracy on training data: {train_accuracy:.2f}\")\n",
        "print(f\"Accuracy on test data: {test_accuracy:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plot_tree(clf, filled=True)\n",
        "plt.show()\n",
        "DecisionTreeClassifier(criterion=\"entropy\")\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "precision_dt = precision_score(y_test, y_pred_dt)\n",
        "recall_dt = recall_score(y_test, y_pred_dt)\n",
        "f1_score_dt = f1_score(y_test, y_pred_dt)\n",
        "confusion_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "clf_rf = RandomForestClassifier()\n",
        "\n",
        "clf_rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = clf_rf.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf = precision_score(y_test, y_pred_rf)\n",
        "recall_rf = recall_score(y_test, y_pred_rf)\n",
        "f1_score_rf = f1_score(y_test, y_pred_rf)\n",
        "confusion_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "print(\"Decision Tree Classifier Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_dt:.2f}\")\n",
        "print(f\"Precision: {precision_dt:.2f}\")\n",
        "print(f\"Recall: {recall_dt:.2f}\")\n",
        "print(f\"F1 Score: {f1_score_dt:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix_dt}\")\n",
        "\n",
        "print(\"\\nRandom Forest Classifier Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_rf:.2f}\")\n",
        "print(f\"Precision: {precision_rf:.2f}\")\n",
        "print(f\"Recall: {recall_rf:.2f}\")\n",
        "print(f\"F1 Score: {f1_score_rf:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix_rf}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "feature_importances = clf.feature_importances_\n",
        "print(\"Feature Importances:\")\n",
        "for feature, importance in zip(X.columns, feature_importances):\n",
        "    print(f\"{feature}: {importance:.2f}\")\n",
        "print(f\"Number of estimators (decision trees): {len(clf.estimators_)}\")\n",
        "\n"
      ]
    }
  ]
}